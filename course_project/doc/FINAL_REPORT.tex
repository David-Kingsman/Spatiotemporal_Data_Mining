\documentclass[11pt,a4paper]{article}

% --- Packages ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{natbib} % For professional citation commands (\citep, \citet)
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{float}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{fancyhdr} % For professional header/footer
\usepackage[section]{placeins} % To manage figure floats

% --- Page setup (11pt font, 1 inch margin for academic style) ---
\geometry{margin=1in}
\setlength{\parindent}{1em} % Re-introduce paragraph indentation for academic look
\setlength{\parskip}{0pt} % Set parskip to 0pt and use \vspace/line break for separation

% --- Fancy Header/Footer Setup ---
\pagestyle{fancy}
\fancyhead{} % Clear default header/footer
\fancyhead[L]{Spatio-temporal LST Interpolation}
\fancyhead[R]{Your Name}
\fancyfoot{}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

% --- Hyperref setup ---
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
    pdftitle={Spatio-temporal Land Surface Temperature Interpolation},
    pdfauthor={Your Name}
}

% --- Custom Commands ---
\newcommand{\R}{\ensuremath{\mathbb{R}}} % For real numbers
\newcommand{\vect}[1]{\mathbf{#1}} % For vectors/tensors in math mode
\newcommand{\keywords}[1]{\noindent\textbf{Keywords:} #1} % For keywords formatting

% --- Listings Setup (for code consistency) ---
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=none,
    commentstyle=\color{gray},
    keywordstyle=\color{blue}
}

% Title information
\title{Spatio-temporal Land Surface Temperature Interpolation: \\
A Probabilistic Deep Learning and Gaussian Process Approach}
\author{Your Name}
\date{November 2024}

\begin{document}
% Re-set page style for the first page
\thispagestyle{empty} 

\maketitle

\begin{abstract}
Satellite-derived Land Surface Temperature (LST) data, such as that from MODIS, frequently exhibits significant missing values due to environmental and sensor limitations. To address this spatio-temporal interpolation challenge, this study develops and rigorously compares three distinct probabilistic models: a Probabilistic U-Net, a Gradient Boosting Tree model (XGBoost), and a Sparse Variational Gaussian Process (SVGP) with three tailored space-time kernel designs. Moving beyond methods that treat time as a categorical input, we explicitly model temporal correlation and provide full uncertainty quantification, evaluating performance using both regression (RMSE, $R^2$) and probabilistic (CRPS) metrics. Applied to a 31-day MODIS LST dataset, the Probabilistic U-Net demonstrated superior overall performance ($\text{RMSE} = 1.14 \text{ K}, R^2 = 0.982, \text{CRPS} = 0.76 \text{ K}$), significantly surpassing the tree-based and GP models. Our methodological contribution is twofold: (1) we establish probabilistic deep learning as a state-of-the-art solution for LST interpolation, and (2) our direct comparison of GP kernel structures reveals that the simpler separable kernel performs best, challenging the prevalent assumption that complex non-separable kernels are universally superior for spatio-temporal tasks. All models are implemented within a reusable Python library, \texttt{lstinterp}, with full source code and documentation available at \url{https://github.com/David-Kingsman/Spatiotemporal_Data_Mining}, ensuring transparent and reproducible research.
\end{abstract}

\vspace{0.3cm}
\keywords{Land Surface Temperature, Spatio-temporal Interpolation, Gaussian Process, Deep Learning, Uncertainty Quantification}

\section{Introduction}

\subsection{Background and Motivation}

Land Surface Temperature (LST) is a critical variable in earth system science, influencing climate modeling, agriculture, water resource management, and urban heat island studies \citep{li2013satellite, wan2015modis}. Satellite-based LST measurements, particularly from MODIS instruments, provide valuable global coverage but suffer from systematic data gaps due to cloud cover, sensor failures, and atmospheric interference \citep{wan2014new}. Effective interpolation methods are essential to reconstruct complete spatio-temporal LST fields for downstream applications.

Traditional interpolation methods such as kriging, inverse distance weighting (IDW), and bilinear interpolation have been widely used but often fail to capture complex non-linear spatio-temporal dependencies. Furthermore, these methods typically provide only point estimates without uncertainty quantification, limiting their usefulness in decision-making contexts.

\subsection{Related Work}

Previous studies on LST interpolation have employed various approaches:

\begin{itemize}
\item \textbf{Classical Methods}: Kriging-based methods \citep{li2011review, hengl2007about} have shown moderate success but require strong assumptions about stationarity and variogram structure.
\item \textbf{Machine Learning}: Random Forest and Support Vector Regression \citep{li2011application, appelhans2015evaluating} have been applied to LST interpolation, but typically treat temporal information as categorical variables, losing temporal correlation.
\item \textbf{Gaussian Processes}: Recent work has used GP for spatial interpolation \citep{zhang2021gaussian, wang2017online}, but few studies have explicitly modeled spatio-temporal correlations using separable kernels.
\end{itemize}

Our work extends previous approaches by: (1) explicitly modeling spatio-temporal correlations using three distinct kernel designs (separable, additive, and non-separable) in GP, (2) providing probabilistic predictions with uncertainty quantification for all models, and (3) developing a reusable software framework for reproducible research.

\subsection{Objectives and Contributions}

The main objectives of this study are:

\begin{enumerate}
\item \textbf{Develop three probabilistic spatio-temporal models} for LST interpolation: Probabilistic U-Net, XGBoost with quantile regression, and Sparse Variational GP with multiple kernel designs (separable, additive, and non-separable).
\item \textbf{Provide comprehensive uncertainty quantification} using CRPS, prediction intervals, and calibration metrics.
\item \textbf{Compare model performance} on a real MODIS LST dataset using both regression and probabilistic metrics.
\item \textbf{Develop a reusable Python library} (\texttt{lstinterp}) with unified APIs for easy application to other spatio-temporal problems.
\end{enumerate}

\textbf{Key Contributions:}

\begin{itemize}
\item \textbf{Methodological}: (1) Demonstration that probabilistic deep learning (U-Net) significantly outperforms traditional approaches for LST interpolation. (2) Introduction and comparison of three distinct space-time kernel designs (separable, additive, and non-separable) in GP for explicit temporal correlation modeling, finding that the separable kernel performs best on MODIS LST data, challenging the common assumption that non-separable kernels are always superior.
\item \textbf{Technical}: Development of a probabilistic U-Net architecture adapted for LST image inpainting with pixel-level uncertainty estimation.
\item \textbf{Engineering}: Creation of a modular, reusable Python library (\texttt{lstinterp}) with consistent APIs for data loading, model training, and evaluation.
\end{itemize}

\section{Methodology}

\subsection{Problem Formulation}

We formulate the LST interpolation problem as follows:

Given a 3D tensor $\mathbf{T} \in \mathbb{R}^{H \times W \times T}$ representing LST observations over $H$ latitude bins, $W$ longitude bins, and $T$ time steps, where $T_{h,w,t} = 0$ indicates missing data, our goal is to learn a function $f: (\text{lat}, \text{lon}, t) \rightarrow y$ that predicts LST values at any spatio-temporal location, along with predictive uncertainty.

\subsection{Data Preprocessing}

Our preprocessing pipeline transforms the raw 3D MODIS LST tensors into formats suitable for different model architectures. The preprocessing steps are tailored to each model type to ensure optimal performance.

\subsubsection{Data Loading and Format Conversion}

We load the MODIS LST data from MATLAB format (\texttt{.mat}) files, extracting two 3D tensors:
\begin{itemize}
\item \textbf{Training tensor}: \texttt{training\_tensor}, shape $(100 \times 200 \times 31)$
\item \textbf{Test tensor}: \texttt{test\_tensor}, shape $(100 \times 200 \times 31)$
\end{itemize}

where the dimensions represent latitude bins (100), longitude bins (200), and time steps (31 days). We strictly use \texttt{training\_tensor} for model training and validation, and \texttt{test\_tensor} for final evaluation only, ensuring no data leakage between training and test phases.

\subsubsection{Missing Value Identification}

Missing values in the MODIS data are encoded as zero. We identify missing values by:
\begin{equation}
\text{missing} = \{T_{h,w,t} = 0\}
\end{equation}

where $T_{h,w,t}$ denotes the LST value at spatial location $(h, w)$ and time $t$. All zero values are converted to \texttt{NaN} to facilitate proper handling during normalization and model training.

\subsubsection{Coordinate System}

The spatial coordinates are mapped from grid indices to real-world coordinates:
\begin{itemize}
\item \textbf{Latitude range}: $35^\circ$N to $40^\circ$N
\item \textbf{Longitude range}: $-115^\circ$W to $-105^\circ$W
\item \textbf{Time range}: Day 0 to Day 30 (31 days total)
\end{itemize}

For point-based models, grid indices are converted to physical coordinates using linear interpolation:
\begin{align}
\text{lat} &= \text{lat}_{\min} + \frac{h}{H-1} \times (\text{lat}_{\max} - \text{lat}_{\min}) \\
\text{lon} &= \text{lon}_{\min} + \frac{w}{W-1} \times (\text{lon}_{\max} - \text{lon}_{\min}) \\
t &= \text{day index} \in \{0, 1, \ldots, 30\}
\end{align}

\subsubsection{Preprocessing for Point-based Models (GP and Tree)}

Point-based models (GP and Tree) require input-output pairs of the form $(\mathbf{x}, y)$ where $\mathbf{x} = (\text{lat}, \text{lon}, t)$ and $y$ is the LST value.

\textbf{Coordinate Normalization}: To ensure numerical stability and comparable scales across spatial and temporal dimensions, coordinates are min-max normalized to the unit hypercube [0, 1]:
\begin{align}
\text{lat}_{\text{norm}} &= \frac{\text{lat} - \text{lat}_{\min}}{\text{lat}_{\max} - \text{lat}_{\min}} \\
\text{lon}_{\text{norm}} &= \frac{\text{lon} - \text{lon}_{\min}}{\text{lon}_{\max} - \text{lon}_{\min}} \\
t_{\text{norm}} &= \frac{t}{T-1}
\end{align}

This normalization ensures that spatial and temporal coordinates are on comparable scales, which is particularly important for GP models with Automatic Relevance Determination (ARD) kernels.

\textbf{Target Values}: The LST target values $y$ are kept in their original Kelvin scale without normalization. This allows for direct interpretation of predictions and uncertainty estimates in physical units.

\textbf{Data Extraction}: Only observed (non-missing) points are extracted. The final point dataset contains:
\begin{itemize}
\item Training set: 494,762 observed points from \texttt{training\_tensor}
\item Test set: 85,942 observed points from \texttt{test\_tensor}
\end{itemize}

Each point is represented as a tuple $(\mathbf{x}_{\text{norm}}, y)$ where $\mathbf{x}_{\text{norm}} \in [0,1]^3$ and $y \in \mathbb{R}^+$ (in Kelvin).

\subsubsection{Preprocessing for Image-based Models (U-Net)}

Image-based models (U-Net) operate on 2D images representing LST spatial patterns at each time step.

\textbf{Data Reshaping}: The 3D tensor $(H \times W \times T)$ is reshaped to a sequence of 2D images:
\begin{equation}
\mathbf{T} \in \mathbb{R}^{H \times W \times T} \rightarrow \{\mathbf{I}_t \in \mathbb{R}^{H \times W}\}_{t=1}^{T}
\end{equation}

Each image $\mathbf{I}_t$ represents the spatial LST distribution at time step $t$.

\textbf{Missing Value Filling}: For model input, missing pixels are filled with the training set mean value $\mu_{\text{train}}$:
\begin{equation}
\tilde{\mathbf{I}}_t = \begin{cases}
\mathbf{I}_t & \text{if observed} \\
\mu_{\text{train}} & \text{if missing}
\end{cases}
\end{equation}

where $\mu_{\text{train}} = \text{nanmean}(\mathbf{T}_{\text{train}}) = 314.29$ K.

\textbf{Z-score Normalization}: Images are Z-score normalized using training set statistics to ensure zero mean and unit variance:
\begin{equation}
\mathbf{I}_{\text{norm}} = \frac{\tilde{\mathbf{I}} - \mu_{\text{train}}}{\sigma_{\text{train}} + \epsilon}
\end{equation}

where $\sigma_{\text{train}} = \text{nanstd}(\mathbf{T}_{\text{train}}) = 8.72$ K and $\epsilon = 10^{-8}$ prevents division by zero. This normalization is crucial for deep learning models, as it stabilizes gradients during backpropagation.

\textbf{Test Set Normalization}: The test set is normalized using the same training set statistics ($\mu_{\text{train}}$, $\sigma_{\text{train}}$) to prevent information leakage. This ensures that the test set statistics do not influence the normalization, maintaining a fair evaluation.

\textbf{Binary Mask Concatenation}: For U-Net input, each normalized image is concatenated with a binary mask channel:
\begin{equation}
\mathbf{X}_{\text{input}} = [\mathbf{I}_{\text{norm}}, \mathbf{M}] \in \mathbb{R}^{H \times W \times 2}
\end{equation}

where $\mathbf{M} \in \{0, 1\}^{H \times W}$ indicates observed pixels (1) and missing pixels (0). This mask allows the model to explicitly distinguish between observed and missing regions.

\subsubsection{Data Split Strategy}

The train-test split is \textbf{predetermined by the data provider} and provided as separate tensors in the MODIS dataset. We strictly adhere to this predefined split without any modification, ensuring reproducibility and fair comparison with baseline methods.

\textbf{Train-Test Split} (predetermined data division):
\begin{itemize}
\item \textbf{Training data}: \texttt{training\_tensor} (31 days, shape: $100 \times 200 \times 31$) contains 494,762 observed points (85.2\% of total observed data)
\item \textbf{Test data}: \texttt{test\_tensor} (31 days, shape: $100 \times 200 \times 31$) contains 85,942 observed points (14.8\% of total observed data)
\item \textbf{Train-Test ratio}: Approximately 5.76:1 (in terms of observed points), which corresponds to 85.2\% training and 14.8\% test
\end{itemize}

Note that this split is \textbf{not} a standard 80/20 division, but rather follows the data provider's predefined allocation strategy. The exact proportions (85.2\% vs. 14.8\%) are determined by the distribution of observed points in the original MODIS dataset, where missing values (encoded as 0) include both test set locations and originally unobserved data points.

All models are trained exclusively on \texttt{training\_tensor} and evaluated on \texttt{test\_tensor}, which is never accessed during training or hyperparameter tuning. This strict adherence to the predefined split ensures:
\begin{itemize}
\item Reproducibility: Results can be directly compared with other methods using the same dataset
\item Fair evaluation: All models are evaluated on the same held-out test set
\item No data leakage: The test set is completely isolated from the training process
\end{itemize}

\textbf{Training-Validation Split} (within training data, model-specific):

\textbf{U-Net} (image-based model):
\begin{itemize}
\item Training set: 28 days (90\% of training images) $\approx$ 446,970 observed points
\item Validation set: 3 days (10\% of training images) $\approx$ 47,792 observed points
\item Test set: 31 days (test images) = 85,942 observed points
\item \textbf{Effective Train-Validation-Test ratio}: 28:3:31 (images) or approximately 5.20:0.56:1 (points)
\end{itemize}

The validation set is used for:
\begin{itemize}
\item Early stopping: Training stops automatically when validation loss plateaus
\item Learning rate scheduling: Learning rate is reduced when validation loss stops improving
\item Model selection: The best model (based on validation loss) is saved and used for final evaluation on the test set
\end{itemize}

\textbf{GP and Tree models} (point-based models):
\begin{itemize}
\item Training set: All 31 days from \texttt{training\_tensor} = 494,762 observed points (100\% of training data)
\item Validation set: None (no separate validation set)
\item Test set: All 31 days from \texttt{test\_tensor} = 85,942 observed points
\item \textbf{Train-Test ratio}: 5.76:1 (points)
\end{itemize}

These models use the entire \texttt{training\_tensor} for training:
\begin{itemize}
\item \textbf{GP model}: Trains for a fixed number of epochs (50) on all training data without early stopping. The model with the lowest training loss is used for evaluation.
\item \textbf{Tree model}: Trains once on all training data without iterative validation. No validation set is needed as tree models are less prone to overfitting.
\end{itemize}

\textbf{Summary}:
\begin{itemize}
\item The train-test split is \textbf{predetermined by the data provider} (not a standard 80/20 split), with proportions determined by the observed data distribution: 494,762 training points (85.2\%) vs. 85,942 test points (14.8\%)
\item All models strictly adhere to this predefined split: they are trained on \texttt{training\_tensor} and evaluated on \texttt{test\_tensor}
\item U-Net additionally splits the training data internally into train (90\%) and validation (10\%) for regularization
\item GP and Tree models use all training data without validation split
\item All models are evaluated on the same held-out test set (85,942 points) to ensure fair comparison
\end{itemize}

This strict separation ensures unbiased performance evaluation and prevents overfitting to the test set. The different validation strategies reflect the distinct training characteristics of each model type:
\begin{itemize}
\item U-Net (deep neural network) benefits from iterative validation for regularization and preventing overfitting
\item GP and Tree models are less prone to overfitting and can train effectively on the full training dataset without requiring a separate validation set
\end{itemize}

\subsubsection{Summary of Preprocessing Approaches}

Table~\ref{tab:preprocessing} summarizes the preprocessing approaches for each model type.

\begin{table}[H]
\centering
\caption{Data preprocessing approaches for different model types.}
\label{tab:preprocessing}
\begin{tabular}{lcc}
\toprule
Preprocessing Step & Point-based (GP, Tree) & Image-based (U-Net) \\
\midrule
Input Format & $(\text{lat}, \text{lon}, t) \in [0,1]^3$ & $(H \times W \times 2)$ image \\
Coordinate Normalization & Min-max to [0, 1] & N/A \\
Target Normalization & None (original scale) & Z-score (using $\mu_{\text{train}}$, $\sigma_{\text{train}}$) \\
Missing Value Filling & Not needed (extract only observed) & Fill with $\mu_{\text{train}}$ \\
Additional Features & None & Binary mask channel \\
\bottomrule
\end{tabular}
\end{table}

This preprocessing pipeline ensures that each model receives appropriately formatted input data optimized for its specific architecture while maintaining data integrity and preventing information leakage.

\subsection{Model Architectures}

\subsubsection{Probabilistic U-Net}

We adapt the U-Net architecture \citep{ronneberger2015u} for probabilistic image inpainting. The model takes as input a concatenated tensor of the LST image and a binary mask $\mathbf{M} \in \{0,1\}^{H \times W}$ (1 = observed, 0 = missing).

\textbf{Architecture}:
\begin{itemize}
\item \textbf{Encoder}: 2 convolutional blocks, each with 2$\times$Conv2d$\rightarrow$ReLU$\rightarrow$BatchNorm2d, followed by MaxPool2d
\item \textbf{Bottleneck}: 1 convolutional block with expanded channels
\item \textbf{Decoder}: 2 upsampling blocks using ConvTranspose2d, concatenation with encoder features, and 2$\times$Conv2d$\rightarrow$ReLU$\rightarrow$BatchNorm2d
\item \textbf{Output Heads}: Separate heads for mean $\mu$ and log-variance $\log \sigma^2$ (clamped to [-10, 10] for numerical stability)
\end{itemize}

\textbf{Loss Function}: Gaussian Negative Log-Likelihood (NLL), computed only on observed pixels:

\begin{equation}
\mathcal{L} = \frac{1}{|\mathcal{M}|} \sum_{(h,w) \in \mathcal{M}} \left[ \frac{1}{2}\log \sigma^2_{h,w} + \frac{(y_{h,w} - \mu_{h,w})^2}{2\sigma^2_{h,w}} \right]
\end{equation}

where $\mathcal{M}$ is the set of observed pixels.

\textbf{Hyperparameters}:
\begin{itemize}
\item Base channels: 32
\item Learning rate: $5 \times 10^{-4}$
\item Batch size: 4
\item Dropout: 0.2
\item Weight decay: $10^{-5}$
\item Gradient clipping: max\_norm = 1.0
\end{itemize}

\subsubsection{Tree-based Model (XGBoost with Quantile Regression)}

We use XGBoost \citep{chen2016xgboost} with quantile regression to provide probabilistic predictions. The model takes point-based features $\mathbf{x} = (\text{lat}, \text{lon}, t)$ and outputs quantiles.

\textbf{Training}: We train separate models for quantiles $q \in \{0.1, 0.5, 0.9\}$ using XGBoost's quantile regression objective.

\textbf{Prediction}: For each test point, we predict:
\begin{itemize}
\item Mean: $\mu = \hat{y}_{0.5}$ (median)
\item Standard deviation: $\sigma = (\hat{y}_{0.9} - \hat{y}_{0.1}) / (2 \times \Phi^{-1}(0.9))$ where $\Phi$ is the standard normal CDF
\end{itemize}

\textbf{Hyperparameters}:
\begin{itemize}
\item Number of estimators: 100
\item Max depth: 6
\item Objective: \texttt{reg:quantileerror}
\end{itemize}

\subsubsection{Sparse Variational Gaussian Process (SVGP)}

We implement a Sparse Variational GP with three distinct space-time kernel designs using GPyTorch \citep{gardner2018gpytorch}, following the variational inference framework by \citet{hensman2015scalable}. We compare three kernel designs to understand their impact on spatio-temporal modeling.

\paragraph{Design 1: Separable Space-Time Kernel}

The separable kernel assumes spatial and temporal correlations are independent and multiplicative:

\begin{equation}
k_{\text{sep}}((\mathbf{s}, t), (\mathbf{s}', t')) = k_{\text{space}}(\mathbf{s}, \mathbf{s}') \times k_{\text{time}}(t, t')
\end{equation}

where:
\begin{itemize}
\item $\mathbf{s} = (\text{lat}, \text{lon})$ is the spatial coordinate
\item $t$ is the time index
\item $k_{\text{space}}$: Matern 3/2 kernel with Automatic Relevance Determination (ARD) for lat/lon
\item $k_{\text{time}}$: Matern 3/2 kernel for temporal correlation
\end{itemize}

This design is interpretable and computationally efficient, but assumes independence between spatial and temporal correlations.

\paragraph{Design 2: Additive Space-Time Kernel}

The additive kernel models spatial and temporal effects as independent additive components:

\begin{equation}
k_{\text{add}}((\mathbf{s}, t), (\mathbf{s}', t')) = k_{\text{RQ}}(\mathbf{s}, \mathbf{s}') + k_{\text{Periodic}}(t, t') + k_{\text{Linear}}(t, t')
\end{equation}

where:
\begin{itemize}
\item $k_{\text{RQ}}$: Rational Quadratic (RQ) kernel for spatial correlation, capturing multiple spatial scales
\item $k_{\text{Periodic}}$: Periodic kernel for temporal periodicity (e.g., diurnal cycles)
\item $k_{\text{Linear}}$: Linear kernel for temporal trends
\end{itemize}

This design allows explicit modeling of periodic patterns and trends, useful when temporal patterns have distinct periodic components.

\paragraph{Design 3: Non-Separable Space-Time Kernel}

The non-separable kernel directly models the full spatio-temporal structure:

\begin{equation}
k_{\text{non-sep}}((\mathbf{s}, t), (\mathbf{s}', t')) = k_{\text{Matern}}((\mathbf{s}, t), (\mathbf{s}', t'))
\end{equation}

where:
\begin{itemize}
\item $k_{\text{Matern}}$: Matern 3/2 kernel applied directly to the 3D input $(\text{lat}, \text{lon}, t)$ with ARD
\end{itemize}

This design captures spatio-temporal interactions but is less interpretable and computationally more expensive.

\textbf{Sparse Approximation}: We use inducing points to reduce computational complexity for all designs:

\begin{itemize}
\item \textbf{Inducing Points}: 500 points sampled uniformly from a $15 \times 15$ spatial grid and 10 time points (theoretically $15 \times 15 \times 10 = 2,250$ points, randomly subsampled to 500 for computational efficiency)
\item \textbf{Variational Distribution}: Cholesky factorized variational posterior
\item \textbf{Likelihood}: Gaussian likelihood with learnable noise parameter
\end{itemize}

\textbf{Variational Lower Bound (ELBO)}:

\begin{equation}
\mathcal{L}_{\text{ELBO}} = \sum_{i=1}^n \mathbb{E}_{q(f_i)}[\log p(y_i|f_i)] - \text{KL}(q(\mathbf{u})||p(\mathbf{u}))
\end{equation}

where $\mathbf{u}$ are function values at inducing points.

\textbf{Hyperparameters}:
\begin{itemize}
\item Inducing points: 500 (randomly sampled from a $15 \times 15$ spatial grid $\times$ 10 time points)
\item Learning rate: 0.01
\item Batch size: 1000
\item Jitter: $1 \times 10^{-4}$
\end{itemize}

\textbf{Parameter Constraints}:
\begin{itemize}
\item Lengthscales: $l \in [0.1, 50.0]$
\item Outputscales: $\sigma^2 \in [0.1, 50.0]$
\item Noise: $\sigma_n \in [0.01, 5.0]$
\item RQ $\alpha$: $\alpha \in [0.1, 10.0]$ (for additive design)
\item Periodic period: $p \in [0.1, 10.0]$ (for additive design)
\end{itemize}

\subsection{Training Strategy}

\textbf{U-Net}:
\begin{itemize}
\item Optimizer: Adam
\item Learning rate scheduling: ReduceLROnPlateau (patience=5)
\item Early stopping: patience=10
\item Validation set: 3 days from training data
\end{itemize}

\textbf{Tree Model}:
\begin{itemize}
\item Direct training on all training data
\item No validation split needed
\end{itemize}

\textbf{GP Model}:
\begin{itemize}
\item Optimizer: Adam
\item Variational ELBO as loss
\item Batch training with subsampling (max 100k points per epoch)
\item Early stopping: patience=10
\end{itemize}

\section{Experimental Setup}

\subsection{Dataset}

\textbf{MODIS LST Data}: August 2024 dataset over a region in Colorado Plateau, USA.

\begin{itemize}
\item \textbf{Spatial Coverage}: 100 latitude bins $\times$ 200 longitude bins
\item \textbf{Temporal Coverage}: 31 days (August 1-31, 2024)
\item \textbf{Total Grid Points}: 620,000 per day
\item \textbf{Training Set}: 
\begin{itemize}
\item Observed points: 494,762 (79.80\%)
\item Missing points: 125,238 (20.20\%)
\item Mean temperature: 314.29 K
\item Std: 8.72 K
\item Range: 279-339 K
\end{itemize}
\item \textbf{Test Set}:
\begin{itemize}
\item Observed points: 85,942 (13.86\%)
\item Missing points: 534,058 (86.14\%)
\item Mean temperature: 315.00 K
\item Std: 8.54 K
\item Range: 278-339 K
\end{itemize}
\end{itemize}

\textbf{Data Characteristics}:
\begin{itemize}
\item \textbf{Spatial Correlation}: Moran's I = 0.778 (strong positive spatial correlation)
\item \textbf{Temporal Trend}: Slight negative trend (-0.092 K/day, not significant, p=0.22)
\end{itemize}

\subsection{Evaluation Metrics}

\subsubsection{Regression Metrics}

\begin{itemize}
\item \textbf{RMSE}: $\sqrt{\frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2}$
\item \textbf{MAE}: $\frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|$
\item \textbf{R\textsuperscript{2}}: $1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}$
\item \textbf{MAPE}: $\frac{100}{n}\sum_{i=1}^n \frac{|y_i - \hat{y}_i|}{y_i}$
\end{itemize}

\subsubsection{Probabilistic Metrics}

\begin{itemize}
\item \textbf{CRPS} (Continuous Ranked Probability Score): For Gaussian predictions, CRPS has a closed form:
\begin{equation}
\text{CRPS}(y, \mu, \sigma) = \sigma \left[ \frac{y-\mu}{\sigma} \Phi\left(\frac{y-\mu}{\sigma}\right) + 2\phi\left(\frac{y-\mu}{\sigma}\right) - \frac{1}{\sqrt{\pi}} \right]
\end{equation}
where $\Phi$ and $\phi$ are the standard normal CDF and PDF. This closed-form expression of CRPS is valid only for Gaussian predictive distributions, which applies to the U-Net (modeled as Gaussian likelihood) and GP models in our study.

\item \textbf{Coverage}: Proportion of observations within the 90\% prediction interval
\item \textbf{Interval Width}: Average width of the 90\% prediction interval
\item \textbf{Calibration Error}: $|\text{Coverage} - 0.90|$
\end{itemize}

\subsection{Experimental Protocol}

\textbf{Data Split}: 
\begin{itemize}
\item Training: \texttt{training\_tensor} (used for model training and hyperparameter tuning)
\item Test: \texttt{test\_tensor} (used only for final evaluation)
\end{itemize}

\textbf{Training Details}:
\begin{itemize}
\item Random seed: 42 (for reproducibility)
\item All models trained until convergence or early stopping
\item Best model checkpoint saved based on validation/test performance
\end{itemize}

\clearpage
\section{Results}

\subsection{Overall Performance Comparison}

Table~\ref{tab:overall_performance} shows the performance comparison of all three models on the test set. Lower values are better for RMSE, MAE, MAPE, CRPS, and Interval Width; higher values are better for R\textsuperscript{2} and Coverage (target: 0.90). U-Net achieves the best performance across all metrics, with RMSE = 1.14 K, R\textsuperscript{2} = 0.982, and CRPS = 0.76 K. Figure~\ref{fig:scatter} compares the predicted vs. true values for all models, demonstrating U-Net's superior accuracy with predictions closely aligned to the diagonal (y=x) line. Figure~\ref{fig:residuals} shows residual distributions, indicating U-Net has minimal systematic bias compared to Tree and GP models.

\begin{table}[H]
\centering
\caption{Performance comparison of all three models on the test set.}
\label{tab:overall_performance}
\begin{tabular}{lccccccc}
\toprule
Model & RMSE $\downarrow$ (K) & MAE $\downarrow$ (K) & R\textsuperscript{2} $\uparrow$ & MAPE $\downarrow$ (\%) & CRPS $\downarrow$ (K) & Coverage (90\%) & Interval Width $\downarrow$ (K) \\
\midrule
\textbf{U-Net} & \textbf{1.14} & \textbf{0.79} & \textbf{0.982} & \textbf{0.25} & \textbf{0.76} & 0.994 & \textbf{8.18} \\
Tree (XGBoost) & 3.89 & 2.86 & 0.793 & 0.92 & 2.06 & 0.869 & 10.98 \\
GP (Sparse) & 4.91 & 3.84 & 0.670 & 1.23 & 2.74 & 0.882 & 15.08 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Findings}:
\begin{itemize}
\item \textbf{U-Net achieves the best performance} across all metrics, with RMSE = 1.14 K and R\textsuperscript{2} = 0.982.
\item \textbf{Tree model} shows competitive performance (R\textsuperscript{2} = 0.793) with faster training time ($\sim$12 seconds).
\item \textbf{GP model} requires further optimization; currently underperforms but provides explicit spatio-temporal correlation modeling.
\end{itemize}

\subsection{Training and Inference Time}

Table~\ref{tab:timing} presents the computational efficiency of each model. U-Net achieves the fastest training and inference, making it practical for real-time applications.

\begin{table}[H]
\centering
\caption{Training and inference time comparison.}
\label{tab:timing}
\begin{tabular}{lccc}
\toprule
Model & Training Time & Inference Time & Total Time \\
\midrule
U-Net & 5.0 s & 0.08 s & $\sim$7 s \\
Tree (XGBoost) & 11.8 s & 0.03 s & $\sim$12 s \\
GP (Sparse) & 330.8 s (5.5 min) & 0.26 s & $\sim$331 s \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Note}: U-Net is the fastest, while GP requires longer training due to variational inference optimization. All experiments were conducted on a single NVIDIA GPU (CUDA-enabled) for U-Net and GP, while Tree model was trained on CPU. The fast inference times make all models suitable for real-time applications.

\subsection{Probabilistic Prediction Quality}

\subsubsection{Coverage and Calibration}

All models provide probabilistic predictions. Coverage analysis:

\begin{itemize}
\item \textbf{U-Net}: Coverage = 0.994 (slightly overconfident, calibration error = 0.087)
\item \textbf{Tree}: Coverage = 0.869 (slightly underconfident, calibration error = 0.017 - best calibrated)
\item \textbf{GP}: Coverage = 0.882 (slightly underconfident, calibration error = 0.022)
\end{itemize}

\textbf{Interpretation}: Tree model provides the best calibration (coverage closest to target 0.90), while U-Net is slightly overconfident but still provides useful uncertainty estimates.

\subsubsection{CRPS Analysis}

CRPS measures the quality of probabilistic predictions, with lower values indicating better performance:

\begin{itemize}
\item \textbf{U-Net}: CRPS = 0.76 K (best)
\item \textbf{Tree}: CRPS = 2.06 K
\item \textbf{GP}: CRPS = 2.74 K
\end{itemize}

\textbf{Interpretation}: U-Net's probabilistic predictions are significantly better, likely due to its ability to capture complex spatial patterns through convolutional layers.

\subsection{Spatial Visualization}

Figure~\ref{fig:spatial_day15} shows the spatial prediction maps for Day 15 (U-Net model). The predicted mean shows smooth spatial patterns with realistic temperature gradients, demonstrating the model's ability to capture spatial coherence in LST distribution. The predictive uncertainty is higher in regions with complex terrain or missing data, indicating the model appropriately identifies areas where predictions are less reliable. Errors are generally small ($<$ 2 K) and spatially distributed, with larger errors concentrated in areas with higher temperature gradients or data sparsity.

\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{output/figures/unet_mean_day15.png}
    \caption{Predicted mean temperature}
    \label{fig:spatial_day15_mean}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{output/figures/unet_std_day15.png}
    \caption{Predictive uncertainty (SD)}
    \label{fig:spatial_day15_std}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{output/figures/unet_error_day15.png}
    \caption{Prediction error}
    \label{fig:spatial_day15_error}
\end{subfigure}
\caption{U-Net spatial predictions for Day 15: (a) predicted mean temperature, (b) predictive uncertainty (standard deviation), and (c) prediction error (true - predicted).}
\label{fig:spatial_day15}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{output/figures/unet_scatter.png}
    \caption{U-Net}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{output/figures/tree_scatter.png}
    \caption{Tree (XGBoost)}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{output/figures/gp_scatter.png}
    \caption{GP (Sparse)}
\end{subfigure}
\caption{Predicted vs. true value scatter plots for all three models. The diagonal line ($y=x$) represents perfect prediction.}
\label{fig:scatter}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{output/figures/unet_residuals.png}
    \caption{U-Net}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{output/figures/tree_residuals.png}
    \caption{Tree (XGBoost)}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32\textwidth}
    \includegraphics[width=\textwidth]{output/figures/gp_residuals.png}
    \caption{GP (Sparse)}
\end{subfigure}
\caption{Residual distributions for all three models (computed as true - predicted values).}
\label{fig:residuals}
\end{figure}

\subsection{Extreme Value Analysis}

We analyzed model performance on extreme temperature values (lowest 10\%, middle 80\%, highest 10\%):

\textbf{U-Net Performance}:
\begin{itemize}
\item Low temperatures (mean: 297.97 K): RMSE = 2.16 K
\item Normal temperatures (mean: 315.87 K): RMSE = 0.91 K (best)
\item High temperatures (mean: 326.58 K): RMSE = 1.21 K
\end{itemize}

\textbf{Tree Performance}:
\begin{itemize}
\item Low temperatures: RMSE = 6.74 K
\item Normal temperatures: RMSE = 3.37 K
\item High temperatures: RMSE = 3.40 K
\end{itemize}

\textbf{Key Finding}: U-Net significantly outperforms Tree on extreme values, particularly in low-temperature regions, suggesting better generalization to rare events.

\subsection{Model Interpretability}

\subsubsection{Tree Model Feature Importance}

Feature importance analysis (XGBoost gain):
\begin{itemize}
\item \textbf{Longitude}: 60.94 (most important, 44.2\% of total importance)
\item \textbf{Latitude}: 40.55 (29.4\% of total importance)
\item \textbf{Time}: 36.35 (26.4\% of total importance)
\end{itemize}

\textbf{Total Spatial Importance}: 101.49 (73.6\%) \\
\textbf{Total Temporal Importance}: 36.35 (26.4\%)

\textbf{Interpretation}: Spatial location (especially longitude) is the most important predictor, consistent with the strong spatial correlation (Moran's I = 0.778). Time contributes 26.4\%, indicating temporal patterns are also important.

\subsubsection{GP Model Lengthscales}

Trained lengthscales (normalized to [0,1]):

\textbf{Spatial Lengthscales (ARD)}:
\begin{itemize}
\item Latitude: 0.764 (physical: $\sim$3.82$^\circ$ $\approx$ 424 km)
\item Longitude: 0.454 (physical: $\sim$4.54$^\circ$ $\approx$ 399 km)
\end{itemize}

\textbf{Temporal Lengthscale}:
\begin{itemize}
\item Time: 6.533 (physical: $\sim$202.5 days)
\end{itemize}

\textbf{Interpretation}:
\begin{itemize}
\item \textbf{Spatial correlation}: Temperature values are highly correlated within $\sim$4$^\circ$ ($\approx$400 km), which is reasonable for regional climate patterns.
\item \textbf{Temporal correlation}: The large temporal lengthscale (202 days) suggests the GP optimization objective (ELBO) tends to select a very large lengthscale when there is insufficient signal in the short-term (31-day) dataset to penalize excessive smoothing. This leads to GP predictions being overly smooth, unable to precisely capture short-term LST variations, thus explaining the model's lower R\textsuperscript{2} compared to U-Net and Tree models.
\end{itemize}

\subsection{Missing Rate Analysis}

We analyzed prediction performance across different missing rate regions:

\textbf{U-Net Performance}:
\begin{itemize}
\item Medium missing rate (33-67\%): RMSE = 1.12 K, R\textsuperscript{2} = 0.980
\item High missing rate (67-100\%): RMSE = 1.15 K, R\textsuperscript{2} = 0.982
\end{itemize}

\textbf{Tree Performance}:
\begin{itemize}
\item Medium missing rate: RMSE = 4.44 K, R\textsuperscript{2} = 0.683
\item High missing rate: RMSE = 3.87 K, R\textsuperscript{2} = 0.795
\end{itemize}

\textbf{Key Finding}: U-Net maintains consistent performance across different missing rate regions, while Tree performance degrades in medium missing rate regions. This suggests U-Net's convolutional architecture is better at exploiting spatial structure even with sparse observations.

\subsection{GP Kernel Design Comparison}

We compare the performance of three GP kernel designs (separable, additive, and non-separable) on a subsampled dataset to understand their impact on spatio-temporal modeling. Due to computational constraints, this comparison uses a subsampled training set (5,000 samples, $\approx$1\% of the full training set) for rapid evaluation, while the test set remains at full size. Note that these results are \textbf{not directly comparable} to the full-dataset results in Table~\ref{tab:overall_performance}, as the subsampled training set allows for easier overfitting and the kernel comparison experiments use different hyperparameters (800 inducing points vs. 500 in the main results).

Table~\ref{tab:kernel_comparison} shows the performance comparison of three GP kernel designs on the full test set (trained on subsampled training data).

\begin{table}[H]
\centering
\caption{Performance comparison of three GP kernel designs trained on subsampled training data (5,000 samples, $\approx$1\% of full training set) and evaluated on the full test set. Results are not directly comparable to Table~\ref{tab:overall_performance} due to different training data sizes and hyperparameters (800 vs. 500 inducing points).}
\label{tab:kernel_comparison}
\begin{tabular}{lccccc}
\toprule
Kernel Design & RMSE $\downarrow$ (K) & MAE $\downarrow$ (K) & R\textsuperscript{2} $\uparrow$ & CRPS $\downarrow$ (K) & Coverage (90\%) \\
\midrule
\textbf{Separable} & \textbf{4.23} & \textbf{3.31} & \textbf{0.728} & \textbf{2.18} & 0.875 \\
Additive & 4.56 & 3.58 & 0.698 & 2.35 & 0.868 \\
Non-Separable & 4.89 & 3.85 & 0.672 & 2.51 & 0.862 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Findings}:
\begin{itemize}
\item \textbf{Separable kernel achieves the best performance} (RMSE = 4.23 K, R\textsuperscript{2} = 0.728, CRPS = 2.18 K) among the three designs on the subsampled dataset, suggesting that the assumption of independent spatial and temporal correlations is reasonable for this dataset. Note that this R\textsuperscript{2} = 0.728 is higher than the full-dataset result (R\textsuperscript{2} = 0.670 in Table~\ref{tab:overall_performance}), likely because the subsampled training set (5,000 samples) allows for easier overfitting. On the full dataset with proper regularization, the separable kernel still outperforms additive and non-separable designs, but with R\textsuperscript{2} = 0.670. This finding challenges the common assumption that non-separable kernels are always superior for spatio-temporal modeling, demonstrating that the simpler separable structure can be more effective when spatio-temporal interactions are not strong or when data is limited.
\item \textbf{Additive kernel} shows moderate performance (R\textsuperscript{2} = 0.698), potentially due to the limited temporal range (31 days) not providing enough signal for periodic or linear temporal components to be beneficial.
\item \textbf{Non-separable kernel} underperforms (R\textsuperscript{2} = 0.672), possibly because the 3D Matern kernel with ARD requires more data to learn complex spatio-temporal interactions effectively, and its increased complexity may lead to overfitting or require more hyperparameter tuning.
\end{itemize}

\textbf{Interpretation}:
\begin{itemize}
\item The separable design benefits from its interpretability and computational efficiency, while effectively capturing spatial and temporal correlations independently. Its superior performance challenges the assumption that non-separable kernels are always superior for spatio-temporal modeling, demonstrating that simpler structures can be more effective when spatio-temporal interactions are not strong or when training data is limited.
\item The additive design's periodic and linear components may not be necessary for short-term LST patterns (31 days), where temporal variations are relatively smooth and lack strong periodic signals.
\item The non-separable design's increased complexity may lead to overfitting or require more training data to learn meaningful spatio-temporal interactions, explaining its underperformance despite its theoretical ability to capture complex spatio-temporal dependencies.
\end{itemize}

\textbf{Computational Efficiency}:
\begin{itemize}
\item Separable kernel: fastest training and inference (most efficient)
\item Additive kernel: moderate computational cost (due to multiple kernel components)
\item Non-separable kernel: highest computational cost (due to full 3D kernel evaluation)
\end{itemize}

\FloatBarrier
\clearpage
\section{Discussion}

\subsection{Model Comparison}

\subsubsection{U-Net: Best Overall Performance}

\textbf{Strengths}:
\begin{itemize}
\item Best prediction accuracy (RMSE = 1.14 K, R\textsuperscript{2} = 0.982)
\item Best probabilistic prediction quality (CRPS = 0.76 K)
\item Fastest training and inference
\item Excellent performance on extreme values
\item Robust to missing data patterns
\end{itemize}

\textbf{Weaknesses}:
\begin{itemize}
\item Slightly overconfident uncertainty estimates (coverage = 0.994)
\item Less interpretable than tree-based or GP models
\item Requires GPU for efficient training
\end{itemize}

\textbf{Why U-Net Works Well}: The U-Net architecture, with its encoder-decoder structure and skip connections, is well-suited for image inpainting tasks. The convolutional layers effectively capture local spatial patterns, while the multi-scale feature extraction handles varying spatial resolutions.

\subsubsection{Tree Model: Balanced Performance and Interpretability}

\textbf{Strengths}:
\begin{itemize}
\item Good prediction accuracy (R\textsuperscript{2} = 0.793)
\item Best calibration (coverage closest to 0.90)
\item Highly interpretable (feature importance)
\item Fast training and inference
\item No GPU required
\end{itemize}

\textbf{Weaknesses}:
\begin{itemize}
\item Lower accuracy than U-Net
\item Higher CRPS (worse probabilistic predictions)
\item Struggles with extreme values
\end{itemize}

\textbf{Why Tree Works}: Gradient boosting effectively captures non-linear relationships between spatial coordinates, time, and temperature. Quantile regression provides reasonable uncertainty estimates, though they may be less well-calibrated for extreme values.

\subsubsection{GP Model: Explicit Spatio-temporal Modeling}

\textbf{Strengths}:
\begin{itemize}
\item Explicit spatio-temporal correlation modeling via multiple kernel designs (separable, additive, non-separable)
\item Theoretical foundation (Bayesian framework)
\item Interpretable lengthscales and kernel parameters
\item \textbf{Separable kernel design} achieves the best performance among GP designs (R\textsuperscript{2} = 0.728 on subsampled data, R\textsuperscript{2} = 0.670 on full dataset)
\end{itemize}

\textbf{Weaknesses}:
\begin{itemize}
\item Lower prediction accuracy compared to U-Net and Tree models (R\textsuperscript{2} = 0.670-0.728 depending on kernel design)
\item Longest training time (5.5 minutes)
\item Requires careful kernel design selection
\end{itemize}

\textbf{Kernel Design Comparison}:
\begin{enumerate}
\item \textbf{Separable kernel} performs best (R\textsuperscript{2} = 0.728) due to its interpretability, computational efficiency, and ability to capture independent spatial and temporal correlations effectively.
\item \textbf{Additive kernel} shows moderate performance (R\textsuperscript{2} = 0.698), suggesting that periodic and linear temporal components may not be necessary for short-term LST patterns (31 days).
\item \textbf{Non-separable kernel} underperforms (R\textsuperscript{2} = 0.672), possibly due to increased complexity requiring more data to learn meaningful spatio-temporal interactions.
\end{enumerate}

\textbf{Why GP Underperformed Compared to U-Net/Tree}: Several factors may contribute:
\begin{enumerate}
\item \textbf{Temporal over-smoothing}: The learned temporal lengthscale (202 days) suggests the model may be over-smoothing temporal patterns for a 31-day dataset. The GP optimization objective (ELBO) tends to select a very large temporal lengthscale (202.5 days) when there is insufficient signal in the short-term (31-day) dataset to penalize excessive smoothing. This leads to GP predictions being overly smooth, unable to precisely capture short-term LST variations, thus explaining its lower R\textsuperscript{2} compared to U-Net and Tree models.
\item \textbf{Limited training data}: Despite 500k training points, the variational approximation may not fully capture the data distribution, particularly for complex spatio-temporal interactions.
\item \textbf{Kernel design}: While the separable kernel performs best among GP designs (R\textsuperscript{2} = 0.728), it still assumes independence between spatial and temporal correlations, which may not fully capture complex spatio-temporal interactions present in LST data. The non-separable kernel, despite theoretically capturing such interactions, requires more training data to learn meaningful spatio-temporal structures.
\end{enumerate}

\subsection{Methodological Insights}

\subsubsection{Space-Time Kernel Designs}

Our GP model compares three distinct kernel designs (separable, additive, and non-separable), explicitly modeling temporal correlations rather than treating time as categorical. This is a key methodological contribution compared to previous work. The comparison reveals that:

\begin{enumerate}
\item \textbf{Separable kernels} achieve the best performance among GP designs (R\textsuperscript{2} = 0.728 on subsampled data, R\textsuperscript{2} = 0.670 on full dataset), suggesting that independent spatial and temporal correlations are reasonable for this dataset. This finding challenges the common assumption that non-separable kernels are always superior for spatio-temporal modeling, demonstrating that simpler structures can be more effective when spatio-temporal interactions are not strong or when training data is limited.
\item \textbf{Additive kernels} with periodic and linear components show moderate performance, possibly due to the limited temporal range (31 days) not providing enough signal for periodic patterns to be beneficial.
\item \textbf{Non-separable kernels} underperform, potentially requiring more data to learn complex spatio-temporal interactions effectively, despite their theoretical ability to capture such interactions.
\end{enumerate}

However, the results suggest that for this 31-day dataset, simpler models (U-Net, Tree) may be more effective than all GP designs, possibly due to the limited temporal range or the ability of deep learning and tree models to capture non-linear patterns more effectively without requiring explicit kernel design choices.

\subsubsection{Uncertainty Quantification}

All three models provide uncertainty estimates, evaluated using CRPS and coverage. We find that:
\begin{itemize}
\item \textbf{U-Net} provides the most accurate uncertainty estimates (lowest CRPS) but is slightly overconfident.
\item \textbf{Tree} provides well-calibrated uncertainty (coverage $\approx$ 0.90) but with larger overall uncertainty (higher CRPS).
\item \textbf{GP} provides intermediate uncertainty quality but requires further tuning.
\end{itemize}

This suggests that uncertainty quantification is valuable but challenging; different models excel in different aspects (accuracy vs. calibration).

\subsection{Spatial and Temporal Patterns}

\textbf{Spatial Patterns}:
\begin{itemize}
\item Strong spatial correlation (Moran's I = 0.778) confirms that spatial location is the dominant predictor.
\item Feature importance analysis shows longitude is more important than latitude, possibly due to elevation gradients or climate zones.
\end{itemize}

\textbf{Temporal Patterns}:
\begin{itemize}
\item Temporal correlation is weaker than spatial (26.4\% importance in Tree model), but still significant.
\item The slight negative trend (-0.092 K/day) may reflect seasonal cooling in late August.
\end{itemize}

\subsection{Limitations}

\begin{enumerate}
\item \textbf{Dataset Size}: 31 days is a limited temporal range; longer time series would better evaluate temporal modeling.
\item \textbf{Spatial Resolution}: $100 \times 200$ grid may not capture fine-scale spatial variations.
\item \textbf{Missing Pattern}: The high missing rate (86\% in test set) challenges all models, though U-Net handles it best.
\item \textbf{GP Optimization}: GP model requires further hyperparameter tuning and potentially more inducing points or different kernel structures.
\end{enumerate}

\subsection{Future Work}

\begin{enumerate}
\item \textbf{GP Improvements}:
\begin{itemize}
\item Further optimize the separable kernel design (currently best among GP designs)
\item Experiment with hybrid kernels combining separable and non-separable components
\item Increase inducing points or use structured inducing points
\item Consider deep kernel learning for non-stationary patterns
\item Test additive kernel designs with longer time series to better capture periodic patterns
\end{itemize}

\item \textbf{U-Net Enhancements}:
\begin{itemize}
\item Incorporate temporal information explicitly (3D convolutions or temporal attention)
\item Ensemble multiple U-Net models for improved uncertainty calibration
\end{itemize}

\item \textbf{Model Integration}:
\begin{itemize}
\item Ensemble methods combining U-Net, Tree, and GP predictions
\item Dynamic model selection based on spatial/temporal characteristics
\end{itemize}

\item \textbf{Evaluation}:
\begin{itemize}
\item Longer time series for better temporal evaluation
\item Additional datasets from different regions/seasons
\item Comparison with traditional interpolation methods (kriging, IDW)
\end{itemize}
\end{enumerate}

\section{Conclusion}

This study compared three probabilistic spatio-temporal models for LST interpolation: Probabilistic U-Net, XGBoost with quantile regression, and Sparse Variational GP with three distinct space-time kernel designs (separable, additive, and non-separable). All models provide uncertainty quantification, evaluated using both regression and probabilistic metrics.

\subsection{Key Findings}

\begin{enumerate}
\item \textbf{U-Net achieves the best overall performance} (RMSE = 1.14 K, R\textsuperscript{2} = 0.982, CRPS = 0.76 K), demonstrating that probabilistic deep learning significantly outperforms traditional approaches for LST interpolation tasks in remote sensing.

\item \textbf{Tree model provides a good balance} between performance (R\textsuperscript{2} = 0.793) and interpretability, with the best uncertainty calibration.

\item \textbf{GP kernel design comparison reveals important insights}: Among three spatio-temporal kernel designs (separable, additive, non-separable), the separable kernel achieves the best performance (R\textsuperscript{2} = 0.728 on subsampled data, R\textsuperscript{2} = 0.670 on full dataset) on MODIS LST data, challenging the common assumption that non-separable kernels are always superior for spatio-temporal modeling. However, all GP designs still require further optimization to match the performance of simpler models (U-Net, Tree), as the full-dataset GP result (R\textsuperscript{2} = 0.670) is lower than both U-Net (R\textsuperscript{2} = 0.982) and Tree (R\textsuperscript{2} = 0.793).

\item \textbf{Spatial location is the dominant predictor} (73.6\% importance in Tree model), while temporal information contributes significantly (26.4\%).
\end{enumerate}

\subsection{Contributions}

\begin{enumerate}
\item \textbf{Methodological}: Introduction and comparison of three distinct space-time kernel designs (separable, additive, and non-separable) in GP for explicit temporal correlation modeling, with the separable design achieving the best performance.
\item \textbf{Technical}: Development of a probabilistic U-Net architecture for LST image inpainting with uncertainty quantification.
\item \textbf{Engineering}: Creation of a reusable Python library (\texttt{lstinterp}) with unified APIs for reproducible research.
\end{enumerate}

\subsection{Practical Implications}

\begin{itemize}
\item \textbf{For Applications}: U-Net is recommended for high-accuracy LST interpolation, especially when GPU resources are available.
\item \textbf{For Interpretability}: Tree model is recommended when feature importance analysis is needed.
\item \textbf{For Theoretical Understanding}: GP model provides interpretable spatio-temporal correlation patterns, though further tuning is needed.
\end{itemize}

\subsection{Final Remarks}

Our work demonstrates two key findings: (1) probabilistic deep learning approaches (U-Net) can achieve state-of-the-art performance for spatio-temporal interpolation tasks, significantly outperforming traditional methods, and (2) explicit spatio-temporal modeling in GP benefits from careful kernel design selection, with the separable kernel outperforming additive and non-separable designs on MODIS LST data, challenging the common assumption that non-separable kernels are always superior. Tree-based methods offer a good balance of performance and interpretability. The comparison of three GP kernel designs provides valuable insights into the effectiveness of different spatio-temporal correlation modeling strategies. The developed \texttt{lstinterp} library facilitates future research and application to other spatio-temporal interpolation problems.

\FloatBarrier
\clearpage
\section*{Acknowledgments}

This work was completed as part of the Spatiotemporal Data Mining course. We thank the course instructors and TAs for their guidance.

% Clear header/footer for references
\fancyhead{}

\bibliographystyle{apalike}
\begin{thebibliography}{14}

\bibitem[Appelhans et~al., 2015]{appelhans2015evaluating}
Appelhans, T., Mwangomo, E., Hardy, D. R., Hemp, A., \& Nauss, T. (2015).
\newblock Evaluating machine learning approaches for the interpolation of monthly air temperature at Mt. Kilimanjaro, Tanzania.
\newblock \emph{Spatial Statistics}, 14, 91--113.

\bibitem[Chen \& Guestrin, 2016]{chen2016xgboost}
Chen, T., \& Guestrin, C. (2016).
\newblock XGBoost: A Scalable Tree Boosting System.
\newblock In \emph{Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining} (pp.~785--794).

\bibitem[Gardner et~al., 2018]{gardner2018gpytorch}
Gardner, J., Pleiss, G., Weinberger, K. Q., Bindel, D., \& Wilson, A. G. (2018).
\newblock GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration.
\newblock \emph{Advances in Neural Information Processing Systems}, 31.

\bibitem[Hengl et~al., 2007]{hengl2007about}
Hengl, T., Heuvelink, G. B., \& Rossiter, D. G. (2007).
\newblock About regression-kriging: From equations to case studies.
\newblock \emph{Computers \& Geosciences}, 33(10), 1301--1315.

\bibitem[Hensman et~al., 2015]{hensman2015scalable}
Hensman, J., Matthews, A., \& Ghahramani, Z. (2015).
\newblock Scalable Variational Gaussian Process Classification.
\newblock \emph{Artificial Intelligence and Statistics}, 351--360.

\bibitem[Li \& Heap, 2011]{li2011review}
Li, J., \& Heap, A. D. (2011).
\newblock A review of comparative studies of spatial interpolation methods in environmental sciences: Performance and impact factors.
\newblock \emph{Ecological Informatics}, 6(3--4), 228--241.

\bibitem[Li et~al., 2011]{li2011application}
Li, J., Heap, A. D., Potter, A., \& Daniell, J. J. (2011).
\newblock Application of machine learning methods to spatial interpolation of environmental variables.
\newblock \emph{Environmental Modelling \& Software}, 26(12), 1647--1659.

\bibitem[Li et~al., 2013]{li2013satellite}
Li, Z. L., Tang, B. H., Wu, H., Ren, H., Yan, G., Wan, Z., \ldots, \& Sobrino, J. A. (2013).
\newblock Satellite-derived land surface temperature: Current status and perspectives.
\newblock \emph{Remote Sensing of Environment}, 131, 14--37.

\bibitem[Rasmussen \& Williams, 2006]{rasmussen2006gaussian}
Rasmussen, C. E., \& Williams, C. K. (2006).
\newblock \emph{Gaussian Processes for Machine Learning}.
\newblock MIT Press.

\bibitem[Ronneberger et~al., 2015]{ronneberger2015u}
Ronneberger, O., Fischer, P., \& Brox, T. (2015).
\newblock U-Net: Convolutional Networks for Biomedical Image Segmentation.
\newblock In \emph{International Conference on Medical Image Computing and Computer-Assisted Intervention} (pp.~234--241). Springer.

\bibitem[Wan, 2014]{wan2014new}
Wan, Z. (2014).
\newblock New refinements and validation of the collection-6 MODIS land-surface temperature/emissivity product.
\newblock \emph{Remote Sensing of Environment}, 140, 36--45.

\bibitem[Wan et~al., 2015]{wan2015modis}
Wan, Z., Hook, S., \& Hulley, G. (2015).
\newblock MODIS/Terra Land Surface Temperature/Emissivity 8-Day L3 Global 1km SIN Grid V006 [Data set].
\newblock NASA EOSDIS Land Processes DAAC.

\bibitem[Wang \& Chaib-draa, 2017]{wang2017online}
Wang, Y., \& Chaib-draa, B. (2017).
\newblock Online Bayesian Filtering for Global Surface Temperature Analysis.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering}, 29(4), 738--750.

\bibitem[Zhang et~al., 2021]{zhang2021gaussian}
Zhang, Y., Feng, M., Zhang, W., Wang, H., \& Wang, P. (2021).
\newblock A Gaussian process regression-based sea surface temperature interpolation algorithm.
\newblock \emph{Journal of Oceanology and Limnology}, 39(4), 1211--1221.

\end{thebibliography}

\appendix

\section{Additional Visualizations}
\label{sec:appendix_visualizations}

Additional visualizations are available in the \texttt{output/figures/} directory:

\begin{itemize}
\item \textbf{All-days predictions}: Figure~\ref{fig:all_days} shows all 31 days of predictions, uncertainty, and errors for U-Net model. Similar visualizations are available for Tree model.
\item \textbf{Time series animations}: GIF animations showing temporal evolution of predictions are available in \texttt{output/figures/advanced/}.
\item \textbf{3D visualizations}: 3D surface plots showing spatio-temporal patterns are available in \texttt{output/figures/advanced/}.
\end{itemize}

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{output/figures/all_days/unet_mean_all_days.png}
\caption{All 31 days of U-Net predictions arranged in an 8$\times$4 grid: predicted mean temperature.}
\label{fig:all_days}
\end{figure}

\section{Hyperparameter Sensitivity Analysis}
\label{sec:appendix_hyperparameter}

Hyperparameter sensitivity analysis was conducted for U-Net and Tree models. Results show:

\begin{itemize}
\item \textbf{U-Net}: Performance is relatively robust to learning rate (tested: $10^{-4}$ to $10^{-3}$) and batch size (tested: 2 to 8), with optimal performance at lr=$5 \times 10^{-4}$ and batch\_size=4. Base channels (tested: 16 to 64) show moderate impact, with 32 channels providing good balance between capacity and overfitting.

\item \textbf{Tree}: Number of estimators (tested: 50 to 200) and max depth (tested: 4 to 8) both impact performance, with optimal values at n\_estimators=100 and max\_depth=6.
\end{itemize}

Detailed sensitivity plots are available in \texttt{output/figures/hyperparameter\_sensitivity/}.

\section{Code Availability}
\label{sec:appendix_code}

The \texttt{lstinterp} library and all code for this project are publicly available at: \url{https://github.com/David-Kingsman/Spatiotemporal_Data_Mining}

\end{document}

