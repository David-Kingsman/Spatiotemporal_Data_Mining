"""
æ ¸å‡½æ•°è®¾è®¡å¯¹æ¯”å®éªŒ

æ ¹æ® Gemini çš„å»ºè®®ï¼Œå¯¹æ¯”ä¸‰ç§ä¸åŒå¤æ‚åº¦çš„æ—¶ç©ºæ ¸å‡½æ•°è®¾è®¡ï¼š
- Design 1: å¯åˆ†ç¦»æ ¸ k_space Ã— k_time
- Design 2: åŠ æ€§æ ¸ k_RQ(space) + k_Periodic(time) + k_Linear(time)
- Design 3: éåˆ†ç¦»æ ¸ k_Matern(3D input)

è¿™ä¸ªè„šæœ¬å°†è®­ç»ƒä¸‰ç§ä¸åŒçš„è®¾è®¡ï¼Œå¹¶åœ¨ç›¸åŒçš„æ•°æ®ä¸Šè¯„ä¼°å®ƒä»¬çš„æ€§èƒ½ã€‚
"""

import os
import sys
import time
import numpy as np
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# æ£€æŸ¥å¹¶å¯¼å…¥ gpytorch
try:
    import gpytorch
    from gpytorch.mlls import VariationalELBO
    GPYTORCH_AVAILABLE = True
except ImportError:
    print("âš ï¸  è­¦å‘Š: éœ€è¦å®‰è£… gpytorch æ‰èƒ½è¿è¡Œæ­¤è„šæœ¬")
    print("   è¯·è¿è¡Œ: pip install gpytorch")
    GPYTORCH_AVAILABLE = False
    gpytorch = None
    VariationalELBO = None

from lstinterp.data.modis import load_modis_tensor, MODISDataset
from lstinterp.models.gp_st import GPSTModel, GPSTConfig, create_inducing_points
from lstinterp.metrics.probabilistic import crps_gaussian
from lstinterp.utils import set_seed

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt


def print_section_header(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)


def evaluate_model(model, test_dataset, device='cpu'):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½
    
    è¿”å›:
    metrics: dictï¼ŒåŒ…å«å„ç§è¯„ä¼°æŒ‡æ ‡
    """
    model.eval()
    model.likelihood.eval()
    
    # æ”¶é›†æ‰€æœ‰æµ‹è¯•æ•°æ®
    test_values = []
    test_coords = []
    
    for i in range(len(test_dataset)):
        coords, value = test_dataset[i]
        test_coords.append(coords.numpy())
        test_values.append(value.item())
    
    test_coords = torch.tensor(np.array(test_coords), dtype=torch.float32, device=device)
    test_values = np.array(test_values)
    
    # æ‰¹é‡é¢„æµ‹ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰
    batch_size = 1000
    means = []
    stds = []
    
    with torch.no_grad():
        for i in range(0, len(test_coords), batch_size):
            batch_coords = test_coords[i:i+batch_size]
            mean_batch, std_batch = model.predict(batch_coords)
            means.append(mean_batch.cpu().numpy())
            stds.append(std_batch.cpu().numpy())
    
    mean = np.concatenate(means)
    std = np.concatenate(stds)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    rmse = np.sqrt(np.mean((test_values - mean) ** 2))
    mae = np.mean(np.abs(test_values - mean))
    mape = np.mean(np.abs((test_values - mean) / (test_values + 1e-8))) * 100
    
    ss_res = np.sum((test_values - mean) ** 2)
    ss_tot = np.sum((test_values - np.mean(test_values)) ** 2)
    r2 = 1 - (ss_res / (ss_tot + 1e-8))
    
    # CRPS
    crps = np.mean(crps_gaussian(test_values, mean, std))
    
    # é¢„æµ‹åŒºé—´è¦†ç›–ç‡ï¼ˆ90%ï¼‰
    lower = mean - 1.645 * std  # 5%åˆ†ä½æ•°
    upper = mean + 1.645 * std  # 95%åˆ†ä½æ•°
    coverage = np.mean((test_values >= lower) & (test_values <= upper))
    interval_width = np.mean(upper - lower)
    
    return {
        'rmse': rmse,
        'mae': mae,
        'mape': mape,
        'r2': r2,
        'crps': crps,
        'coverage': coverage,
        'interval_width': interval_width,
        'mean': mean,
        'std': std,
        'true_values': test_values
    }


def train_model(config, train_dataset, device='cpu', verbose=True):
    """
    è®­ç»ƒ GP æ¨¡å‹
    
    è¿”å›:
    model: è®­ç»ƒå¥½çš„æ¨¡å‹
    train_time: è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰
    """
    if verbose:
        print(f"\nè®­ç»ƒ {config.kernel_design} è®¾è®¡...")
    
    start_time = time.time()
    
    # åˆ›å»ºè¯±å¯¼ç‚¹
    n_space = int(np.sqrt(config.num_inducing // 10))  # å‡è®¾10ä¸ªæ—¶é—´ç‚¹
    n_time = min(10, 31)  # é™åˆ¶æ—¶é—´ç‚¹æ•°é‡
    
    inducing_points = create_inducing_points(
        n_space=n_space,
        n_time=n_time,
        normalize=True
    ).to(device)
    
    # åˆ›å»ºæ¨¡å‹
    model = GPSTModel(
        inducing_points=inducing_points,
        config=config,
        lengthscale_space=0.5,
        lengthscale_time=0.3,
        outputscale=10.0,
        noise=1.0,
        alpha=1.0,  # RQ æ ¸å‚æ•°ï¼ˆä»…ç”¨äº additive è®¾è®¡ï¼‰
        period=1.0  # Periodic æ ¸å‚æ•°ï¼ˆä»…ç”¨äº additive è®¾è®¡ï¼‰
    ).to(device)
    
    # ä¼˜åŒ–å™¨
    model.train()
    model.likelihood.train()
    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)
    
    # è®­ç»ƒå¾ªç¯ï¼ˆç®€åŒ–ç‰ˆï¼Œä½¿ç”¨è¾ƒå°‘çš„æ•°æ®ä»¥åŠ å¿«é€Ÿåº¦ï¼‰
    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=config.batch_size, shuffle=True
    )
    
    # é™åˆ¶è®­ç»ƒæ•°æ®é‡ï¼ˆç”¨äºå¯¹æ¯”å®éªŒï¼‰
    max_train_samples = 5000  # ä½¿ç”¨å‰5000ä¸ªæ ·æœ¬è¿›è¡Œå¿«é€Ÿè®­ç»ƒ
    train_samples = min(len(train_dataset), max_train_samples)
    
    if not GPYTORCH_AVAILABLE:
        raise ImportError("éœ€è¦å®‰è£… gpytorch æ‰èƒ½è®­ç»ƒæ¨¡å‹")
    
    mll = VariationalELBO(
        model.likelihood, model.gp, num_data=train_samples
    )
    
    for epoch in range(min(config.num_epochs, 20)):  # é™åˆ¶æœ€å¤§è®­ç»ƒè½®æ•°
        epoch_loss = 0.0
        n_batches = 0
        
        for batch_idx, (coords, values) in enumerate(train_loader):
            if batch_idx * config.batch_size >= max_train_samples:
                break
            
            coords = coords.to(device)
            values = values.to(device)
            
            optimizer.zero_grad()
            output = model(coords)
            loss = -mll(output, values)
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            n_batches += 1
        
        if verbose and (epoch + 1) % 5 == 0:
            print(f"  Epoch {epoch + 1}/{config.num_epochs}, Loss: {epoch_loss / n_batches:.4f}")
    
    train_time = time.time() - start_time
    
    return model, train_time


def compare_kernel_designs(data_path: str = None, output_dir: str = None):
    """
    å¯¹æ¯”ä¸‰ç§æ ¸å‡½æ•°è®¾è®¡
    
    å‚æ•°:
    data_path: MODISæ•°æ®è·¯å¾„
    output_dir: è¾“å‡ºç›®å½•
    """
    # è®¾ç½®éšæœºç§å­
    set_seed(42)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ•°æ®è·¯å¾„
    if data_path is None:
        data_path = project_root / "modis_aug_data" / "MODIS_Aug.mat"
    if output_dir is None:
        output_dir = project_root / "output" / "kernel_comparison"
    
    os.makedirs(output_dir, exist_ok=True)
    
    print_section_header("æ ¸å‡½æ•°è®¾è®¡å¯¹æ¯”å®éªŒ")
    
    # åŠ è½½æ•°æ®
    print("\nåŠ è½½æ•°æ®...")
    training_tensor = load_modis_tensor(str(data_path), key="training_tensor")
    test_tensor = load_modis_tensor(str(data_path), key="test_tensor")
    
    print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {training_tensor.shape}")
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_tensor.shape}")
    
    # åˆ›å»ºæ•°æ®é›†ï¼ˆä½¿ç”¨ç‚¹æ¨¡å¼ï¼‰
    train_dataset = MODISDataset(training_tensor, mode="point")
    test_dataset = MODISDataset(test_tensor, mode="point")
    
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")
    
    # ä¸‰ç§æ ¸å‡½æ•°è®¾è®¡é…ç½®
    designs = [
        {
            'name': 'Design 1: å¯åˆ†ç¦»æ ¸',
            'config': GPSTConfig(
                kernel_design="separable",
                kernel_space="matern32",
                kernel_time="matern32",
                num_inducing=800,
                lr=0.01,
                num_epochs=30,
                batch_size=1000
            )
        },
        {
            'name': 'Design 2: åŠ æ€§æ ¸',
            'config': GPSTConfig(
                kernel_design="additive",
                kernel_space="matern32",  # ç”¨äº fallback
                kernel_time="matern32",   # ç”¨äº fallback
                num_inducing=800,
                lr=0.01,
                num_epochs=30,
                batch_size=1000
            )
        },
        {
            'name': 'Design 3: éåˆ†ç¦»æ ¸',
            'config': GPSTConfig(
                kernel_design="non_separable",
                kernel_space="matern32",
                kernel_time="matern32",
                num_inducing=800,
                lr=0.01,
                num_epochs=30,
                batch_size=1000
            )
        }
    ]
    
    # å­˜å‚¨ç»“æœ
    results = {}
    
    print_section_header("è®­ç»ƒå’Œè¯„ä¼°æ‰€æœ‰è®¾è®¡")
    
    # å¯¹æ¯ç§è®¾è®¡è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°
    for design in designs:
        print(f"\n{'='*80}")
        print(f"  å¤„ç†: {design['name']}")
        print(f"{'='*80}")
        
        try:
            # è®­ç»ƒæ¨¡å‹
            model, train_time = train_model(
                design['config'], 
                train_dataset, 
                device=device,
                verbose=True
            )
            
            print(f"\nè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {train_time:.2f}ç§’")
            
            # è¯„ä¼°æ¨¡å‹
            print("\nè¯„ä¼°æ¨¡å‹æ€§èƒ½...")
            metrics = evaluate_model(model, test_dataset, device=device)
            
            # å­˜å‚¨ç»“æœ
            results[design['name']] = {
                'config': design['config'],
                'train_time': train_time,
                'metrics': metrics,
                'model': model  # ä¿å­˜æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
            }
            
            # æ‰“å°ç»“æœ
            print(f"\n{design['name']} è¯„ä¼°ç»“æœ:")
            print(f"  RMSE: {metrics['rmse']:.4f} K")
            print(f"  MAE: {metrics['mae']:.4f} K")
            print(f"  RÂ²: {metrics['r2']:.4f}")
            print(f"  MAPE: {metrics['mape']:.4f} %")
            print(f"  CRPS: {metrics['crps']:.4f} K")
            print(f"  90% é¢„æµ‹åŒºé—´è¦†ç›–ç‡: {metrics['coverage']:.4f}")
            print(f"  å¹³å‡åŒºé—´å®½åº¦: {metrics['interval_width']:.4f} K")
            print(f"  è®­ç»ƒæ—¶é—´: {train_time:.2f} ç§’")
            
        except Exception as e:
            print(f"\nâš ï¸  è®¾è®¡ {design['name']} è®­ç»ƒå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print_section_header("ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š")
    
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”è¡¨:")
    print("-" * 120)
    print(f"{'è®¾è®¡':<30} {'RMSE â†“':<12} {'MAE â†“':<12} {'RÂ² â†‘':<12} {'CRPS â†“':<12} {'Coverage':<12} {'è®­ç»ƒæ—¶é—´':<12}")
    print("-" * 120)
    
    for design_name, result in results.items():
        m = result['metrics']
        print(f"{design_name:<30} {m['rmse']:<12.4f} {m['mae']:<12.4f} {m['r2']:<12.4f} "
              f"{m['crps']:<12.4f} {m['coverage']:<12.4f} {result['train_time']:<12.2f}")
    
    print("-" * 120)
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    results_file = output_dir / "kernel_comparison_results.txt"
    with open(results_file, 'w', encoding='utf-8') as f:
        f.write("æ ¸å‡½æ•°è®¾è®¡å¯¹æ¯”å®éªŒç»“æœ\n")
        f.write("=" * 80 + "\n\n")
        
        for design_name, result in results.items():
            f.write(f"{design_name}\n")
            f.write("-" * 80 + "\n")
            m = result['metrics']
            f.write(f"RMSE: {m['rmse']:.4f} K\n")
            f.write(f"MAE: {m['mae']:.4f} K\n")
            f.write(f"RÂ²: {m['r2']:.4f}\n")
            f.write(f"MAPE: {m['mape']:.4f} %\n")
            f.write(f"CRPS: {m['crps']:.4f} K\n")
            f.write(f"90% é¢„æµ‹åŒºé—´è¦†ç›–ç‡: {m['coverage']:.4f}\n")
            f.write(f"å¹³å‡åŒºé—´å®½åº¦: {m['interval_width']:.4f} K\n")
            f.write(f"è®­ç»ƒæ—¶é—´: {result['train_time']:.2f} ç§’\n\n")
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    # ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–
    if len(results) > 0:
        print("\nç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–...")
        try:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            
            design_names = list(results.keys())
            rmse_values = [results[d]['metrics']['rmse'] for d in design_names]
            mae_values = [results[d]['metrics']['mae'] for d in design_names]
            r2_values = [results[d]['metrics']['r2'] for d in design_names]
            crps_values = [results[d]['metrics']['crps'] for d in design_names]
            
            # RMSEå¯¹æ¯”
            axes[0, 0].bar(design_names, rmse_values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
            axes[0, 0].set_title('RMSE å¯¹æ¯” (è¶Šå°è¶Šå¥½)', fontsize=14, fontweight='bold')
            axes[0, 0].set_ylabel('RMSE (K)')
            axes[0, 0].tick_params(axis='x', rotation=15)
            axes[0, 0].grid(axis='y', alpha=0.3)
            
            # MAEå¯¹æ¯”
            axes[0, 1].bar(design_names, mae_values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
            axes[0, 1].set_title('MAE å¯¹æ¯” (è¶Šå°è¶Šå¥½)', fontsize=14, fontweight='bold')
            axes[0, 1].set_ylabel('MAE (K)')
            axes[0, 1].tick_params(axis='x', rotation=15)
            axes[0, 1].grid(axis='y', alpha=0.3)
            
            # RÂ²å¯¹æ¯”
            axes[1, 0].bar(design_names, r2_values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
            axes[1, 0].set_title('RÂ² å¯¹æ¯” (è¶Šå¤§è¶Šå¥½)', fontsize=14, fontweight='bold')
            axes[1, 0].set_ylabel('RÂ²')
            axes[1, 0].tick_params(axis='x', rotation=15)
            axes[1, 0].grid(axis='y', alpha=0.3)
            
            # CRPSå¯¹æ¯”
            axes[1, 1].bar(design_names, crps_values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
            axes[1, 1].set_title('CRPS å¯¹æ¯” (è¶Šå°è¶Šå¥½)', fontsize=14, fontweight='bold')
            axes[1, 1].set_ylabel('CRPS (K)')
            axes[1, 1].tick_params(axis='x', rotation=15)
            axes[1, 1].grid(axis='y', alpha=0.3)
            
            plt.tight_layout()
            fig.savefig(output_dir / "kernel_designs_comparison.png", dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {output_dir / 'kernel_designs_comparison.png'}")
        except Exception as e:
            print(f"âš ï¸  ç”Ÿæˆå¯è§†åŒ–æ—¶å‡ºé”™: {str(e)}")
    
    print_section_header("å®éªŒå®Œæˆ")
    print("\nâœ… æ ¸å‡½æ•°è®¾è®¡å¯¹æ¯”å®éªŒå·²å®Œæˆï¼")
    print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
    
    return results


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æ ¸å‡½æ•°è®¾è®¡å¯¹æ¯”å®éªŒ")
    parser.add_argument("--data_path", type=str, default=None, help="MODISæ•°æ®è·¯å¾„")
    parser.add_argument("--output_dir", type=str, default=None, help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # ç¡®ä¿å¯¼å…¥gpytorchï¼ˆå¦‚æœå¯ç”¨ï¼‰
    try:
        import gpytorch
        compare_kernel_designs(
            data_path=args.data_path,
            output_dir=args.output_dir
        )
    except ImportError:
        print("âš ï¸  è­¦å‘Š: éœ€è¦å®‰è£… gpytorch æ‰èƒ½è¿è¡Œæ­¤è„šæœ¬")
        print("   è¯·è¿è¡Œ: pip install gpytorch")
        sys.exit(1)

