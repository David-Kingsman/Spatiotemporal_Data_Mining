"""
è®­ç»ƒæ ‘æ¨¡å‹Baselineï¼ˆTree-based Baseline Modelsï¼‰

æœ¬è„šæœ¬å®ç°äº†åŸºäºæ ‘æ¨¡å‹çš„baselineæ–¹æ³•ï¼Œç”¨äºMODISåœ°è¡¨æ¸©åº¦æ•°æ®çš„æ’å€¼å’Œé¢„æµ‹ã€‚

æ”¯æŒçš„æ¨¡å‹ï¼š
1. XGBoostï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰ï¼šæ¢¯åº¦æå‡æ ‘ï¼Œæ”¯æŒåˆ†ä½æ•°å›å½’
2. Random Forestï¼ˆå¤‡ç”¨ï¼‰ï¼šéšæœºæ£®æ—ï¼Œä¸æ”¯æŒåˆ†ä½æ•°å›å½’ï¼ˆä½¿ç”¨æ ‡å‡†å·®ä¼°è®¡ä¸ç¡®å®šæ€§ï¼‰

ä¸»è¦ç‰¹ç‚¹ï¼š
1. åˆ†ä½æ•°å›å½’ï¼ˆXGBoostï¼‰ï¼šæä¾›é¢„æµ‹åˆ†ä½æ•°ï¼ˆ10%, 50%, 90%ï¼‰å’Œä¸ç¡®å®šæ€§ä¼°è®¡
2. æ ‡å‡†å·®ä¼°è®¡ï¼ˆRandom Forestï¼‰ï¼šä½¿ç”¨ä¸ªä½“æ ‘é¢„æµ‹çš„æ ‡å‡†å·®ä¼°è®¡ä¸ç¡®å®šæ€§
3. å¿«é€Ÿè®­ç»ƒå’Œé¢„æµ‹ï¼šæ ‘æ¨¡å‹è®­ç»ƒé€Ÿåº¦å¿«ï¼Œé€‚åˆä½œä¸ºbaseline

æ•°æ®æ ¼å¼ï¼š
- è¾“å…¥ï¼š3ç»´å¼ é‡ (H, W, T) = (100, 200, 31)
  - H: çº¬åº¦ç»´åº¦ï¼ˆ35Â°-40Â°Nï¼‰
  - W: ç»åº¦ç»´åº¦ï¼ˆ-115Â°--105Â°Wï¼‰
  - T: æ—¶é—´ç»´åº¦ï¼ˆ31å¤©ï¼‰
- è¾“å‡ºï¼šæ¸©åº¦å€¼ï¼ˆå•ä½ï¼šKelvinï¼‰
- ç¼ºå¤±å€¼ï¼šç”¨0è¡¨ç¤º

è¯„ä¼°æŒ‡æ ‡ï¼š
- å›å½’æŒ‡æ ‡ï¼šRMSE, MAE, RÂ², MAPE
- æ¦‚ç‡æŒ‡æ ‡ï¼šCRPS, 90%é¢„æµ‹åŒºé—´è¦†ç›–ç‡, æ ¡å‡†è¯¯å·®

ä½œè€…ï¼šlstinterpå›¢é˜Ÿ
åˆ›å»ºæ—¶é—´ï¼š2024å¹´
"""
import numpy as np
import sys
import os
from pathlib import Path
import json
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from lstinterp.data import load_modis_tensor, MODISDataset
from lstinterp.models import TreeBaseline, TreeConfig
from lstinterp.metrics import compute_regression_metrics, compute_probabilistic_metrics
from lstinterp.viz import plot_prediction_scatter, plot_residuals
from lstinterp.utils import set_seed

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_DIR = Path("output")
OUTPUT_DIR.mkdir(exist_ok=True)
(OUTPUT_DIR / "results").mkdir(exist_ok=True)
(OUTPUT_DIR / "figures").mkdir(exist_ok=True)
(OUTPUT_DIR / "models").mkdir(exist_ok=True)


def print_section_header(title, width=80):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "=" * width)
    print(f"  {title}")
    print("=" * width)


def main():
    """ä¸»å‡½æ•°ï¼šè®­ç»ƒå’Œè¯„ä¼°æ ‘æ¨¡å‹"""
    start_time = time.time()
    experiment_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    print_section_header("å®éªŒé…ç½®", width=80)
    print(f"å®éªŒæ—¶é—´: {experiment_time}")
    print(f"éšæœºç§å­: 42")
    
    set_seed(42)
    
    # æ£€æŸ¥ä¾èµ–åº“
    print("\nä¾èµ–åº“æ£€æŸ¥:")
    try:
        import xgboost
        print(f"  âœ… XGBoost: {xgboost.__version__}")
        xgb_available = True
    except ImportError:
        print("  âš ï¸  XGBoostæœªå®‰è£…ï¼Œå°†ä½¿ç”¨Random Forest")
        xgb_available = False
    
    try:
        import numpy as np
        print(f"  âœ… NumPy: {np.__version__}")
    except ImportError:
        print("  âŒ NumPyæœªå®‰è£…")
        return
    
    try:
        from sklearn.ensemble import RandomForestRegressor
        import sklearn
        print(f"  âœ… scikit-learn: {sklearn.__version__}")
    except ImportError:
        print("  âŒ scikit-learnæœªå®‰è£…")
        return
    # åŠ è½½æ•°æ®
    print_section_header("æ•°æ®åŠ è½½")
    data_path = "modis_aug_data/MODIS_Aug.mat"
    print(f"æ•°æ®è·¯å¾„: {data_path}")
    
    print("\nåŠ è½½è®­ç»ƒæ•°æ®...")
    train_tensor = load_modis_tensor(data_path, "training_tensor")
    H, W, T = train_tensor.shape
    print(f"è®­ç»ƒæ•°æ®ç»´åº¦: {H} Ã— {W} Ã— {T}")
    
    print("\nåŠ è½½æµ‹è¯•æ•°æ®...")
    test_tensor = load_modis_tensor(data_path, "test_tensor")
    print(f"æµ‹è¯•æ•°æ®ç»´åº¦: {H} Ã— {W} Ã— {T}")
    
    # åˆ›å»ºæ•°æ®é›†
    print_section_header("æ•°æ®é¢„å¤„ç†")
    print("è½¬æ¢ä¸ºç‚¹æ•°æ®æ ¼å¼ (lat, lon, time) â†’ temperature")
    
    print("\nåˆ›å»ºè®­ç»ƒæ•°æ®é›†...")
    train_dataset = MODISDataset(train_tensor, mode="point")
    print(f"  - è®­ç»ƒè§‚æµ‹ç‚¹æ•°: {len(train_dataset):,}")
    
    print("\nåˆ›å»ºæµ‹è¯•æ•°æ®é›†...")
    test_dataset = MODISDataset(test_tensor, mode="point")
    print(f"  - æµ‹è¯•è§‚æµ‹ç‚¹æ•°: {len(test_dataset):,}")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    print("\næå–è®­ç»ƒæ•°æ®...")
    X_train = np.array([train_dataset[i][0].numpy() for i in range(len(train_dataset))])
    y_train = np.array([train_dataset[i][1].numpy() for i in range(len(train_dataset))])
    
    print(f"  - è¾“å…¥ç‰¹å¾ç»´åº¦: {X_train.shape}")
    print(f"    * ç‰¹å¾1 (çº¬åº¦): èŒƒå›´ [{X_train[:, 0].min():.2f}, {X_train[:, 0].max():.2f}]")
    print(f"    * ç‰¹å¾2 (ç»åº¦): èŒƒå›´ [{X_train[:, 1].min():.2f}, {X_train[:, 1].max():.2f}]")
    print(f"    * ç‰¹å¾3 (æ—¶é—´): èŒƒå›´ [{X_train[:, 2].min():.0f}, {X_train[:, 2].max():.0f}] å¤©")
    print(f"  - ç›®æ ‡å˜é‡ç»´åº¦: {y_train.shape}")
    print(f"    * æ¸©åº¦èŒƒå›´: [{y_train.min():.2f}, {y_train.max():.2f}] K")
    print(f"    * æ¸©åº¦å‡å€¼: {y_train.mean():.2f} K")
    print(f"    * æ¸©åº¦æ ‡å‡†å·®: {y_train.std():.2f} K")
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    print("\næå–æµ‹è¯•æ•°æ®...")
    X_test = np.array([test_dataset[i][0].numpy() for i in range(len(test_dataset))])
    y_test = np.array([test_dataset[i][1].numpy() for i in range(len(test_dataset))])
    
    print(f"  - è¾“å…¥ç‰¹å¾ç»´åº¦: {X_test.shape}")
    print(f"    * ç‰¹å¾1 (çº¬åº¦): èŒƒå›´ [{X_test[:, 0].min():.2f}, {X_test[:, 0].max():.2f}]")
    print(f"    * ç‰¹å¾2 (ç»åº¦): èŒƒå›´ [{X_test[:, 1].min():.2f}, {X_test[:, 1].max():.2f}]")
    print(f"    * ç‰¹å¾3 (æ—¶é—´): èŒƒå›´ [{X_test[:, 2].min():.0f}, {X_test[:, 2].max():.0f}] å¤©")
    print(f"  - ç›®æ ‡å˜é‡ç»´åº¦: {y_test.shape}")
    print(f"    * æ¸©åº¦èŒƒå›´: [{y_test.min():.2f}, {y_test.max():.2f}] K")
    print(f"    * æ¸©åº¦å‡å€¼: {y_test.mean():.2f} K")
    print(f"    * æ¸©åº¦æ ‡å‡†å·®: {y_test.std():.2f} K")
    
    # è®­ç»ƒæ¨¡å‹
    print_section_header("æ¨¡å‹é…ç½®å’Œè®­ç»ƒ")
    
    # é€‰æ‹©æ¨¡å‹ç±»å‹
    if xgb_available:
        model_type = "xgb"
        print("âœ… ä½¿ç”¨XGBoostæ¨¡å‹")
        print("  - æ”¯æŒåˆ†ä½æ•°å›å½’")
        print("  - æä¾›ä¸ç¡®å®šæ€§ä¼°è®¡")
    else:
        model_type = "rf"
        print("âš ï¸  ä½¿ç”¨Random Forestæ¨¡å‹ï¼ˆXGBoostä¸å¯ç”¨ï¼‰")
        print("  - ä½¿ç”¨æ ‡å‡†å·®ä¼°è®¡ä¸ç¡®å®šæ€§")
    
    config = TreeConfig(
        model_type=model_type,
        n_estimators=100,
        quantile_regression=(model_type != "rf"),  # RFä¸æ”¯æŒåˆ†ä½æ•°å›å½’
        quantiles=[0.1, 0.5, 0.9] if model_type != "rf" else None
    )
    
    print("\næ¨¡å‹è¶…å‚æ•°:")
    print(f"  - æ¨¡å‹ç±»å‹: {config.model_type}")
    print(f"  - æ ‘çš„æ•°é‡: {config.n_estimators}")
    print(f"  - åˆ†ä½æ•°å›å½’: {config.quantile_regression}")
    if config.quantile_regression:
        print(f"  - åˆ†ä½æ•°: {config.quantiles}")
    
    # è®­ç»ƒ
    print("\nå¼€å§‹è®­ç»ƒ...")
    training_start_time = time.time()
    model = TreeBaseline(config)
    model.fit(X_train, y_train)
    training_time = time.time() - training_start_time
    print(f"âœ… è®­ç»ƒå®Œæˆ (è€—æ—¶: {training_time:.2f} ç§’)")
    
    # é¢„æµ‹
    print_section_header("æ¨¡å‹é¢„æµ‹")
    prediction_start_time = time.time()
    print("è¿›è¡Œé¢„æµ‹...")
    y_pred_mean, y_pred_std = model.predict_with_uncertainty(X_test)
    prediction_time = time.time() - prediction_start_time
    print(f"âœ… é¢„æµ‹å®Œæˆ (è€—æ—¶: {prediction_time:.2f} ç§’)")
    print(f"  - é¢„æµ‹ç‚¹æ•°: {len(y_pred_mean):,}")
    
    # è¯„ä¼°
    print_section_header("æ¨¡å‹è¯„ä¼°")
    print("è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
    reg_metrics = compute_regression_metrics(y_test, y_pred_mean)
    prob_metrics = compute_probabilistic_metrics(y_test, y_pred_mean, y_pred_std)
    
    all_metrics = {**reg_metrics, **prob_metrics}
    
    # æ·»åŠ å®éªŒä¿¡æ¯
    all_metrics["experiment_info"] = {
        "experiment_time": experiment_time,
        "random_seed": 42,
        "training_time_seconds": training_time,
        "prediction_time_seconds": prediction_time,
        "model_config": {
            "model_type": config.model_type,
            "n_estimators": config.n_estimators,
            "quantile_regression": config.quantile_regression,
            "quantiles": config.quantiles if config.quantile_regression else None
        },
        "data_info": {
            "train_points": len(X_train),
            "test_points": len(X_test)
        }
    }
    
    print("\n" + "=" * 80)
    print("  è¯„ä¼°ç»“æœ")
    print("=" * 80)
    
    # å›å½’æŒ‡æ ‡
    print("\nã€å›å½’æŒ‡æ ‡ã€‘")
    print(f"  {'æŒ‡æ ‡':<30} {'å€¼':<15} {'è¯´æ˜':<30}")
    print("-" * 75)
    print(f"  {'RMSE (Root Mean Squared Error)':<30} {reg_metrics['rmse']:<15.4f} {'è¶Šå°è¶Šå¥½ï¼Œå•ä½: Kelvin'}")
    print(f"  {'MAE (Mean Absolute Error)':<30} {reg_metrics['mae']:<15.4f} {'è¶Šå°è¶Šå¥½ï¼Œå•ä½: Kelvin'}")
    print(f"  {'RÂ² (Coefficient of Determination)':<30} {reg_metrics['r2']:<15.4f} {'è¶Šå¤§è¶Šå¥½ï¼ŒèŒƒå›´: (-âˆ, 1]'}")
    print(f"  {'MAPE (Mean Absolute Percentage Error)':<30} {reg_metrics['mape']:<15.4f} {'è¶Šå°è¶Šå¥½ï¼Œå•ä½: %'}")
    
    # æ¦‚ç‡æŒ‡æ ‡
    print("\nã€æ¦‚ç‡é¢„æµ‹æŒ‡æ ‡ã€‘")
    print(f"  {'æŒ‡æ ‡':<30} {'å€¼':<15} {'è¯´æ˜':<30}")
    print("-" * 75)
    print(f"  {'CRPS (Continuous Ranked Probability Score)':<30} {prob_metrics['crps']:<15.4f} {'è¶Šå°è¶Šå¥½ï¼Œå•ä½: Kelvin'}")
    print(f"  {'Coverage (90% Prediction Interval)':<30} {prob_metrics['coverage_90']:<15.4f} {'ç›®æ ‡: 0.90'}")
    print(f"  {'Interval Width (90%)':<30} {prob_metrics['interval_width_90']:<15.4f} {'è¶Šå°è¶Šå¥½ï¼Œå•ä½: Kelvin'}")
    print(f"  {'Calibration Error':<30} {prob_metrics['calibration_error']:<15.4f} {'è¶Šå°è¶Šå¥½ï¼Œè¡¡é‡æ ¡å‡†åº¦'}")
    
    # é¢„æµ‹ç»Ÿè®¡
    print("\nã€é¢„æµ‹ç»Ÿè®¡ã€‘")
    print(f"  é¢„æµ‹å‡å€¼:")
    print(f"    - èŒƒå›´: [{y_pred_mean.min():.2f}, {y_pred_mean.max():.2f}] K")
    print(f"    - å‡å€¼: {y_pred_mean.mean():.2f} K")
    print(f"    - æ ‡å‡†å·®: {y_pred_mean.std():.2f} K")
    
    print(f"\n  çœŸå®å€¼:")
    print(f"    - èŒƒå›´: [{y_test.min():.2f}, {y_test.max():.2f}] K")
    print(f"    - å‡å€¼: {y_test.mean():.2f} K")
    print(f"    - æ ‡å‡†å·®: {y_test.std():.2f} K")
    
    print(f"\n  é¢„æµ‹ä¸ç¡®å®šæ€§ (æ ‡å‡†å·®):")
    print(f"    - èŒƒå›´: [{y_pred_std.min():.2f}, {y_pred_std.max():.2f}] K")
    print(f"    - å‡å€¼: {y_pred_std.mean():.2f} K")
    print(f"    - ä¸­ä½æ•°: {np.median(y_pred_std):.2f} K")
    
    # è¯¯å·®åˆ†æ
    errors = y_test - y_pred_mean
    print(f"\nã€è¯¯å·®åˆ†æã€‘")
    print(f"  æ®‹å·® (çœŸå®å€¼ - é¢„æµ‹å€¼):")
    print(f"    - å‡å€¼: {errors.mean():.2f} K (æ¥è¿‘0è¡¨ç¤ºæ— å)")
    print(f"    - æ ‡å‡†å·®: {errors.std():.2f} K")
    print(f"    - èŒƒå›´: [{errors.min():.2f}, {errors.max():.2f}] K")
    print(f"    - ä¸­ä½æ•°: {np.median(errors):.2f} K")
    
    # è¦†ç›–ç‡åˆ†æ
    coverage = prob_metrics['coverage_90']
    target_coverage = 0.90
    coverage_error = abs(coverage - target_coverage)
    print(f"\nã€ä¸ç¡®å®šæ€§æ ¡å‡†ã€‘")
    print(f"  90%é¢„æµ‹åŒºé—´è¦†ç›–ç‡: {coverage:.4f} (ç›®æ ‡: {target_coverage})")
    if coverage_error < 0.05:
        print(f"  âœ… æ ¡å‡†è‰¯å¥½ (è¯¯å·® < 5%)")
    elif coverage_error < 0.10:
        print(f"  âš ï¸  æ ¡å‡†å°šå¯ (è¯¯å·® < 10%)")
    else:
        print(f"  âŒ æ ¡å‡†è¾ƒå·® (è¯¯å·® >= 10%)")
    
    # ä¿å­˜ç»“æœ
    print_section_header("ä¿å­˜ç»“æœ")
    results_path = OUTPUT_DIR / "results" / "tree_results.json"
    with open(results_path, "w") as f:
        json.dump(all_metrics, f, indent=2, ensure_ascii=False)
    print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜: {results_path}")
    
    # ä¿å­˜æ¨¡å‹
    try:
        import pickle
        model_path = OUTPUT_DIR / "models" / f"tree_model_{model_type}.pkl"
        with open(model_path, "wb") as f:
            pickle.dump(model, f)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
        print(f"  - æ¨¡å‹å¤§å°: {model_path.stat().st_size / 1024 / 1024:.2f} MB")
    except Exception as e:
        print(f"âš ï¸  æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
    
    # å¯è§†åŒ–
    print("\nç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    scatter_path = OUTPUT_DIR / "figures" / "tree_scatter.png"
    residuals_path = OUTPUT_DIR / "figures" / "tree_residuals.png"
    
    plot_prediction_scatter(y_test, y_pred_mean, save_path=str(scatter_path))
    print(f"âœ… é¢„æµ‹æ•£ç‚¹å›¾å·²ä¿å­˜: {scatter_path}")
    
    plot_residuals(y_test, y_pred_mean, save_path=str(residuals_path))
    print(f"âœ… æ®‹å·®å›¾å·²ä¿å­˜: {residuals_path}")
    
    # æ€»ç»“
    total_time = time.time() - start_time
    print_section_header("å®éªŒå®Œæˆ")
    print(f"æ€»è€—æ—¶: {total_time:.2f} ç§’ ({total_time/60:.2f} åˆ†é’Ÿ)")
    print(f"  - æ•°æ®åŠ è½½å’Œé¢„å¤„ç†: {training_start_time - start_time:.2f} ç§’")
    print(f"  - æ¨¡å‹è®­ç»ƒ: {training_time:.2f} ç§’")
    print(f"  - æ¨¡å‹é¢„æµ‹: {prediction_time:.2f} ç§’")
    
    print(f"\nä¸»è¦æŒ‡æ ‡æ€»ç»“:")
    print(f"  - RÂ²: {reg_metrics['r2']:.4f}")
    print(f"  - RMSE: {reg_metrics['rmse']:.4f} K")
    print(f"  - CRPS: {prob_metrics['crps']:.4f} K")
    print(f"  - è¦†ç›–ç‡(90%): {prob_metrics['coverage_90']:.4f}")
    
    print(f"\næ‰€æœ‰ç»“æœæ–‡ä»¶:")
    print(f"  ğŸ“„ {results_path}")
    if 'model_path' in locals():
        print(f"  ğŸ’¾ {model_path}")
    print(f"  ğŸ“Š {scatter_path}")
    print(f"  ğŸ“Š {residuals_path}")


if __name__ == "__main__":
    main()

